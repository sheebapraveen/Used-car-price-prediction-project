{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f9cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random, sys, time\n",
    "#from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8744e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\anaconda\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\anaconda\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53596825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.46M/6.46M [00:01<00:00, 3.61MB/s]\n",
      "C:\\Users\\PRAVEE~1\\AppData\\Local\\Temp/ipykernel_16508/2160715986.py:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a352de",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.olx.in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d94c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8099feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_button = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/div/div/div[1]/div[2]/div[1]')\n",
    "cars_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16a9626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "950a3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d495ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.cars24.com/\"\n",
    "url2 = \"https://www.cardekho.com/\"\n",
    "url3 = \"https://www.ola.cars/\"\n",
    "url4 = \"https://www.olx.in/cars_c84\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c80d5",
   "metadata": {},
   "source": [
    "Assigned URL into 4 different varibales for the 4 websites we are using to scrape our used car information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b720af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting Data from Cars 24 webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url1)\n",
    "print(\"Legality Response number from Cars 24 URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url1)\n",
    "driver.maximize_window()\n",
    "\n",
    "loc=[\"Delhi\", \"Mumbai\", \"Pune\", \"Bangalore\", \"Hyderabad\", \"Chennai\", \"Kolkata\"]\n",
    "\n",
    "for place in loc:\n",
    "    # select location manually option\n",
    "    WebDriverWait(driver,2).until(ec.element_to_be_clickable((By.XPATH,'//button[contains(text(),\"SELECT MANUALLY\")]'))).click()\n",
    "\n",
    "    # search for location\n",
    "    searchbox = WebDriverWait(driver,2).until(ec.presence_of_element_located((By.XPATH,'//div[@class=\"_6QaMX\"]/input')))\n",
    "    searchbox.send_keys(place)\n",
    "\n",
    "    # confirm click on searched location icon\n",
    "    WebDriverWait(driver,2).until(ec.element_to_be_clickable((By.XPATH,'//ul[@class=\"_16Bvy\"]/li[1]'))).click()\n",
    "\n",
    "    # choose the \"Buy Used Car\" option on the webpage\n",
    "    WebDriverWait(driver,2).until(ec.element_to_be_clickable((By.XPATH,'//a[contains(text(),\"Buy Used Car\")]'))).click()\n",
    "    \n",
    "    scroll_pause_time = 2\n",
    "    screen_height = driver.execute_script(\"return window.screen.height;\")\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "        # scroll one screen height each time\n",
    "        driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "        i += 1\n",
    "        time.sleep(scroll_pause_time)\n",
    "        # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "        scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "        # break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "        if (screen_height) * i > scroll_height:\n",
    "            break \n",
    "        \n",
    "    # fetching urls of every used car on the website\n",
    "    urls = []\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='col-4']//a\"):\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_1l4fi']//a\"):\n",
    "        urls.append(i.get_attribute(\"href\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # obtaining the required data in the empty lists\n",
    "    location = []\n",
    "    year = []\n",
    "    kms_driven = []\n",
    "    car_model = []\n",
    "    owners = []\n",
    "    transmission = []\n",
    "    fuel_type = []\n",
    "    price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # fetching location of used cars\n",
    "    try:\n",
    "        location_tag = driver.find_element_by_xpath(\"//p[@class='_2NHUv']//span\")\n",
    "        location.append(location_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        location.append('None')\n",
    "        \n",
    "    # fetching manufacturing year of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//strong[@class='category']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching number of kms driven of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//div[@class='keyword']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching model name of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//a[@class='_1UhVsV']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching owner details of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//span[@class='_1FH0tX']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching transmission details of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//h2[@class='yhB1nd']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching fuel type of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//div[@class='fMghEO']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching price of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//p[@class='/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/']//span\")\n",
    "        year.append(year_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe and checking the data extracted\n",
    "cars=pd.DataFrame({'place':location,'model':brand,'year':year,'price':price,'km_driven':km,'owners':owners,\n",
    "                   'fuel':fuel,'transmission':transmission})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5529cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting Data from Car Dekho URL webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab237e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url2)\n",
    "print(\"Legality Response number from Car Dekho URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993eceae",
   "metadata": {},
   "source": [
    "Since the legality response from the website is not 200 we cannot perform web scraping here and therefore we shall ignore the further process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url3)\n",
    "print(\"Legality Response number from Ola Cars URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b595f39",
   "metadata": {},
   "source": [
    "Here even though the legality response is 200 we are unable to inspect the webpage as right click is disabled on the website therefore web scraping in such a scenario is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88c256",
   "metadata": {},
   "source": [
    "Collecting Data from OLX Cars webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec276335",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36'}\n",
    "page = requests.get(url4, headers=headers)\n",
    "print(\"Legality Response number from Olx Cars URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ce006",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get(url4)\n",
    "driver.maximize_window()\n",
    "\n",
    "# creating empty lists\n",
    "location = []\n",
    "year = []\n",
    "kms_driven = []\n",
    "car_model = []\n",
    "owners = []\n",
    "transmission = []\n",
    "fuel_type = []\n",
    "price = []\n",
    "\n",
    "# getting the URL of the cars\n",
    "for i in range(0,500):\n",
    "    url=driver.find_elements_by_xpath(\"//ul[@class='rl3f9 _3mXOU']/li/a\")\n",
    "    for i in url:\n",
    "        prod_URL.append(i.get_attribute('href'))\n",
    "    try:\n",
    "        next_btn=driver.find_element_by_xpath(\"//button[@class='rui-39-wj rui-3evoE rui-1JPTg']\").click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "for i in prod_URL:\n",
    "    driver.get(i)    \n",
    "\n",
    "    #Extracting car name\n",
    "    try:\n",
    "        brand.append(driver.find_element_by_xpath(\"//div[@class='_3_knn']/div/span[2]\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        brand.append(\"-\")\n",
    "        \n",
    "    #Extracting the year\n",
    "    try:\n",
    "        year.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_year']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        year.append(\"-\")\n",
    "        \n",
    "    #Extracting the fuel consumed\n",
    "    try:\n",
    "        fuel.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_petrol']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        fuel.append(\"-\")  \n",
    "        \n",
    "    #Extracting the transmission\n",
    "    try:\n",
    "        transmission.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_transmission']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        transmission.append(\"-\") \n",
    "        \n",
    "    #Extracting km driven\n",
    "    try:\n",
    "        km.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_mileage']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        km.append(\"-\") \n",
    "        \n",
    "    #Extracting the price details\n",
    "    try:\n",
    "        price.append(driver.find_element_by_xpath(\"//span[@data-aut-id='itemPrice']\").text.replace('₹',''))\n",
    "    except NoSuchElementException as e:\n",
    "        price.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe and checking the data extracted\n",
    "cars=pd.DataFrame({'place':location,'model':brand,'year':year,'price':price,'km_driven':km,'owners':owners,\n",
    "                   'fuel':fuel,'transmission':transmission})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f44ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.to_csv(\"Used_Cars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3d093",
   "metadata": {},
   "source": [
    "Exported the collected used car details from dataframe to csv format to be used for machine learning model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3250f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
